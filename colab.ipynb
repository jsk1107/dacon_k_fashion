{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "6NVI84w4nWla"
   },
   "source": [
    "## Colab Session 연장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymFuGYCpnWlb"
   },
   "source": [
    "### 아래 코드를 F12를 누른 후 Console에 입력할것 \n",
    "\n",
    "function ClickConnect() {\n",
    "    var buttons = document.querySelectorAll(\"colab-dialog.yes-no-dialog paper-button#cancel\"); \n",
    "    buttons.forEach(function(btn) { \n",
    "        btn.click(); \n",
    "    }); \n",
    "    console.log(\"1분마다 자동 재연결\"); \n",
    "    document.querySelector(\"colab-toolbar-button#connect\").click(); \n",
    "} \n",
    "setInterval(ClickConnect,1000*60);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_2bwC4wrOEP"
   },
   "source": [
    "# CLI 환경 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGXEin_Forr0",
    "outputId": "8c59f47c-b42d-4c70-9208-789c28525dcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kora\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/0d/3d9ab9ee747f0925b038e8350ce137276a7a4730a96a3516485dc1b87ba3/kora-0.9.19-py3-none-any.whl (57kB)\n",
      "\r",
      "\u001b[K     |█████▊                          | 10kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 20kB 18.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 30kB 14.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 40kB 12.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 51kB 9.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 61kB 4.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n",
      "Collecting fastcore\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/98/60404e2817cff113a6ae4023bc1772e23179408fdf7857fa410551758dfe/fastcore-1.3.19-py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 5.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.0.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (54.0.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (20.9)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (19.3.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->kora) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->kora) (0.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (2.4.7)\n",
      "Installing collected packages: fastcore, kora\n",
      "Successfully installed fastcore-1.3.19 kora-0.9.19\n",
      "Console URL: https://teleconsole.com/s/21cb506a7b355bf756b49afbe1942d575c84307e\n"
     ]
    }
   ],
   "source": [
    "!pip install kora\n",
    "from kora import console\n",
    "console.start()  # and click link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lw1HujV_uZxV",
    "outputId": "da0451e8-67ff-4b08-dc28-c42af75c11e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar  7 08:37:46 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P0    33W / 250W |  15965MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbJno14hnWlb"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/jsk1107/dacon_k_fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VoR9LTSrI9t"
   },
   "outputs": [],
   "source": [
    "!pip install -r /content/dacon_k_fashion/requrirement.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAGVOnm3sTM-"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SN6yIKaAsUmt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms as T\n",
    "from torchvision.models.detection.retinanet import RetinaNetClassificationHead\n",
    "from torch.utils.data import Dataset\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCtVRJn40EuM"
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4nFFuCTsJa2"
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "t_wzQD9uqv0w"
   },
   "outputs": [],
   "source": [
    "class KfashionDataset(Dataset):\n",
    "    def __init__(self, img_dir, anno_dir, set_name='train', transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.anno_dir = anno_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.coco = COCO(os.path.join(self.anno_dir, f'{set_name}.json'))\n",
    "\n",
    "        self.image_ids = self.coco.getImgIds()\n",
    "        self.category = self.coco.loadCats(self.coco.getCatIds())\n",
    "\n",
    "    def __getitem__(self, ids):\n",
    "\n",
    "        img = self.get_image(ids)\n",
    "        target = self.get_annotaion(ids)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def get_image(self, ids):\n",
    "        img_info = self.coco.loadImgs(self.image_ids[ids])[0]\n",
    "        key = list(img_info['file_name'])[0]\n",
    "        img_path = os.path.join(self.img_dir, key, img_info['file_name'])\n",
    "        img = Image.open(img_path)\n",
    "        # img = cv2.imread(img_path)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def get_annotaion(self, ids):\n",
    "        anno_ids = self.coco.getAnnIds(imgIds=self.image_ids[ids], iscrowd=False)\n",
    "        coco_annos = self.coco.loadAnns(anno_ids)\n",
    "        target = {}\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        if len(anno_ids) == 0:\n",
    "            print(f'There is not annotation infomation abount Image: {self.image_ids[ids]}')\n",
    "            target['boxes'] = torch.as_tensor([[10, 10, 20, 20]], dtype=torch.float32)\n",
    "            target['labels'] = torch.as_tensor([[0]], dtype=torch.int64)\n",
    "            return target\n",
    "\n",
    "        for coco_anno in coco_annos:\n",
    "            bbox = self.bbox_transform(coco_anno['bbox'])\n",
    "            boxes.append(bbox)\n",
    "            labels.append(coco_anno['category_id'])\n",
    "        target['boxes'] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        target['labels'] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        return target\n",
    "\n",
    "    def bbox_transform(self, bbox):\n",
    "        bbox[2] = bbox[0] + bbox[2]\n",
    "        bbox[3] = bbox[1] + bbox[3]\n",
    "        return bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjzmrMRQsNzH"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZIML99bsOet"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # (역자주: 학습시 50% 확률로 학습 영상을 좌우 반전 변환합니다)\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "\n",
    "img_dir = '/content/train/'\n",
    "anno_dir = '/content/'\n",
    "set_name = 'train'\n",
    "batch_size = 16\n",
    "dataset = KfashionDataset(img_dir, anno_dir, set_name, transforms=get_transform(True))\n",
    "num_classes = len(dataset.category) + 1\n",
    "print(f'num_classes: {num_classes}. 21+1(background)')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "model = retinanet_resnet50_fpn(True)\n",
    "num_anchor = model.anchor_generator.num_anchors_per_location()[0]\n",
    "in_channels = model.head.classification_head.cls_logits.in_channels\n",
    "model.head.classification_head = RetinaNetClassificationHead(in_channels, num_anchor, num_classes)\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.train()\n",
    "for images, targets in dataloader:\n",
    "    optim.zero_grad()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "      model.to(device)\n",
    "      images = list(image.to(device) for image in images)\n",
    "      targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    out = model(images, targets)\n",
    "\n",
    "    cls_loss = out['classification']\n",
    "    reg_loss = out['bbox_regression']\n",
    "\n",
    "    loss = cls_loss + reg_loss\n",
    "    print(f'loss: {loss}')\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4xtPB_3snqH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
